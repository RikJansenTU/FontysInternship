# Ethical Considerations  
The ethical considerations of AI are increasingly being discussed, and there are some very obvious dangers to a tool like this one. Being able to have a celebrity say anything you want them to can create some serious misinformation, like the [AI-generated video of president Zelensky surrendering to Vladimir Putin](https://www.aiaaic.org/aiaaic-repository/ai-and-algorithmic-incidents-and-controversies/president-zelenskyy-deepfake-surrender). 
Right now, a discerning eye will still be able to spot the flaws with relative ease, but when something is posted to social media most people will still accept what they see without giving it a second look, like with the [image of Pope Francis wearing a puffer jacket](https://www.aiaaic.org/aiaaic-repository/ai-and-algorithmic-incidents-and-controversies/deepfake-pope-francis-wears-white-puffa-jacket) that was spread around recently. As these tools advance, the flaws will be harder and harder to spot, making it easier to fool people.

![The AI image of Pope Francis](https://static01.nyt.com/images/2023/04/06/business/00AI-POPE/00AI-POPE-superJumbo.png)  
_The AI generated image of Pope Francis that went viral, created using Midjourney_

I personally have some reservations about this kind of technology, so I tried to use this project as a way to investigate what is currently possible, and how these tools could be abused. I don't actually believe it should be illegal to generate videos of celebrities; parody and satire of well-known people has a long history and can definitely have artistic merit. I do feel like a few safety guidelines should always be kept in mind, and I came up with the following based on my work on this project.

**Private or Internal Use** 
The easiest way of ensuring AI tools don't get abused is to never release them to the wider public, and only use them internally. This is how the app I made is intended to be used, which removes a lot of the potential for misuse, but unfortunately a lot of tools are created specifically to be used by others. If this is the case, I think some other safety measures should be implemented.

**Watermarks and Indicators of Origin**  
I think that when it comes to these ultra-realistic portrayals it should always be clearly indicated that it was generated by AI. Part of this responsibility lies with the person creating the content, who should disclose how it was made (for example by TDE clearly telling those who see the video about its origins).  
The other part of this responsibility lies with the company offering the tools that can be used to create these videos. D-ID automatically adds a watermark to their generated content, but this is very easy to crop out. Ideally, they should add some form of digital 'fingerprint' that can't be removed, something that can be used to definitively establish that it's AI generated. A good next step in development would be adding a watermark of my own to the end result.

**Better Safety Protection**  
I believe any tools facilitating the mimicry of someone's voice or appearance has an obligation to implement certain safety features, like automatically detecting celebrities. This doesn't prevent all abuse - someone could still generate and circulate a video of a colleague saying something offensive. Requiring someone to send in a video giving their permission for their likeness to be used would already be much safer.  
D-ID already has protections in place, although they can still be circuimvented like discussed earlier. Elevenlabs has zero safety measures whatsoever, their official tutorial even showing how to clone Leonardo DiCaprio's voice. 

**Personal Responsibility**
Even just a faked voice fragment has a lot of potential to be used for misinformation, and I believe a company like Elevenlabs has a responsibility to try to minimise this potential as much as possible. Ideally, a comprehensive set of laws will be created to govern AI development and usage, but technology will always outpace regulation, so a large part of the responsibility has to fall on the shoulders of individuals and companies.  
This means TDE, and myself as an extension, have to ensure that the app I created is never used to deceive or misinform. It's also up to me to make sure TDE is aware of the ethical and legal implications a tool like this can have.

### The Future  
There's a lot of elements of this issue that I haven't discussed, but that do warrant potential investigation in the future; not only ethical, but also social and legal, for example with regards to fair use or portrait rights. A lot of these issues don't have clear answers yet considering how relatively new this technology is.

I admit there's a certain conflict in me creating this tool, considering the ethical reservations I have with AI. I do however believe that one of the best way to investigate sociological and ethical impact of a certain technology is to get hands-on experience, seeing what tools are available and how their safety measures can be circuimvented. I've noticed that I'm very interested in examining these types of issues, and it's something I'd like to further explore in the future. AI will be a big theme in the coming years, and there's a lot that's still unclear about how its future will and should look; I'd like to play a part in figuring that out.

### Addendum: Project 3 Analysis
I believe project 3 has a bit less potential for abuse, firstly because the pictures being generated are in the hands of the person depicted in them, and secondly because the general quality and stylization of the end result is much harder to mistake for something real. 
However, there is currently no way to check the identity of the person uploading the training images, and it's easy enough to grab pictures of someone else. Some kind of check, though difficult to implement, would make this aspect of the app safer.  
Also, while I don't believe the results are very realistic, they don't need to be 100% accurate to fool people; if you closely examine the picture of Pope Francis above, it's clearly AI generated, but it was still able to deceive others. Either adding some sort of watermark to the end result, or ensuring that its stylization is sufficiently advanced that it will never look photorealistic, are good ways of avoiding this.
  
_Picture of Michael Jordan as a soccer player generated using the tool I built for project 3_
